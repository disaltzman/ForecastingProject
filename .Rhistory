# Change settings to not use scientific notation
options(scipen = 999)
# Set random seed
set.seed(401)
# Load packages
# Data manipulation.
library(tidyverse)
library(here)
library(lubridate)
library(future)
library(reticulate)
library(kableExtra)
library(tsbox)
library(magrittr)
# Plots
library(ggplot2)
library(patchwork)
# Analyses
library(fpp3)
library(fable.prophet)
# Set plot themes
theme_set(theme_bw())
# Set working directory based upon location of this notebook
i_am("WeeklyHighDemandData.Rmd")
here()
# Change settings to not use scientific notation
options(scipen = 999)
# Set random seed
set.seed(401)
# Load packages
# Data manipulation.
library(tidyverse)
library(here)
library(lubridate)
library(future)
library(reticulate)
library(kableExtra)
library(tsbox)
library(magrittr)
# Plots
library(ggplot2)
library(patchwork)
# Analyses
library(fpp3)
library(fable.prophet)
# Set plot themes
theme_set(theme_bw())
# Set working directory based upon location of this notebook
i_am("WeeklyHighDemandData.Rmd")
# Read in data, remove extranenous columns
df <- read_csv(file="WeeklyHighDemand.csv",show_col_types = F) %>%
select(-7:-12)
# Create weekly dataframe from daily data
df_monthly <- df %>%
group_by(sku, date = yearmonth(transaction_date)) %>%
summarise(gross_units=sum(gross_units,na.rm=TRUE),
gross_orders=sum(gross_orders,na.rm=TRUE),
gross_revenue=sum(gross_revenue,na.rm=TRUE))
# Convert to tsibble
df.ts <- df_monthly %>% as_tsibble(index=date,key=sku)
# There are lots of skus with only a few observations
counts <- df.ts %>%
as_tibble() %>%
group_by(sku) %>%
count() %>%
arrange(desc(n))
# Filter to only those combos with 44 months
df.ts %<>%
group_by(sku) %>%
filter(n()==44)
# Perform Ljung-Box test
lb <- df.ts %>%
as_tibble() %>%
group_by(sku) %>%
summarise(lb_p=ljung_box(gross_units,lag=12)[2])
# How many of the time-series are white noise
lb %<>% filter(lb_p < 0.05) # 2109 are not random noise
# Filter main dataset down to those that are not white noise
df.ts %<>%
group_by(sku) %>%
filter(sku %in% lb$sku)
# Remove large data frames to free up memory
rm(df,df_monthly)
View(df.ts)
# Set working directory based upon location of this notebook
i_am("WeeklyHighDemandData.Rmd")
# Read in data
df <- fread.(file="WeeklyHighDemand.csv") %>%
select.(-7:-12)
# Change settings to not use scientific notation
options(scipen = 999)
# Set random seed
set.seed(401)
# Load packages
# Data manipulation.
library(tidyverse)
library(here)
library(lubridate)
library(future)
library(reticulate)
library(kableExtra)
library(tsbox)
library(magrittr)
# Plots
library(ggplot2)
library(patchwork)
# Analyses
library(fpp3)
library(fable.prophet)
# Set plot themes
theme_set(theme_bw())
# Set working directory based upon location of this notebook
i_am("WeeklyHighDemandData.Rmd")
# Read in data
df <- fread.(file="WeeklyHighDemand.csv") %>%
select.(-7:-12)
# Change settings to not use scientific notation
options(scipen = 999)
# Set random seed
set.seed(401)
# Load packages
# Data manipulation.
library(tidyverse)
library(here)
library(lubridate)
library(future)
library(reticulate)
library(kableExtra)
library(tsbox)
library(magrittr)
# Plots
library(ggplot2)
library(patchwork)
# Analyses
library(fpp3)
library(fable.prophet)
# Set plot themes
theme_set(theme_bw())
# Set working directory based upon location of this notebook
i_am("WeeklyHighDemandData.Rmd")
# Read in data
df <- fread(file="WeeklyHighDemand.csv") %>%
select(-7:-12)
library(data.table)
# Read in data
df <- fread(file="WeeklyHighDemand.csv") %>%
select(-7:-12)
# Create weekly dataframe from daily data
df_weekly <- df %>%
group_by(sku, date = yearweek(transaction_date)) %>%
summarise(gross_units=sum(gross_units,na.rm=TRUE))
# Convert to tsibble
df.ts <- df_weekly %>% as_tsibble(index=date,key=sku)
# Read in data
df <- fread(file="WeeklyHighDemand.csv") %>%
select(-7:-12)
# Create weekly dataframe from daily data
df_weekly <- df %>%
group_by(sku, date = yearweek(transaction_date)) %>%
summarise(gross_units=sum(gross_units,na.rm=TRUE))
# Read in data
df <- fread(file="WeeklyHighDemand.csv") %>%
select(-7:-12)
# Create weekly dataframe from daily data
df_weekly <- df %>%
group_by(sku, date = yearweek(transaction_date)) %>%
summarise(gross_units=sum(gross_units,na.rm=TRUE))
# Convert to tsibble
df.ts <- df_weekly %>%
as_tsibble(index=date,key=sku)
View(df.ts)
source("C:/Users/disal/Desktop/GitHubRepos/ForecastingProject/WeeklyHighDemand/WeeklyHighDemandData.Rmd")
# There are lots of skus with only a few observations
df.ts %>%
as_tibble() %>%
count(sku) %>%
arrange(desc(n))
# Filter to only those combos with 187 weeks
df.ts %<>%
group_by(sku) %>%
filter(n()==187)
# There are lots of skus with only a few observations
counts <- df.ts %>%
as_tibble() %>%
count(sku) %>%
arrange(desc(n))
View(counts)
source("C:/Users/disal/Desktop/GitHubRepos/ForecastingProject/WeeklyHighDemand/WeeklyHighDemandData.Rmd")
# Read in data
df <- fread(file="WeeklyHighDemand.csv") %>%
select(-7:-12)
# Create weekly dataframe from daily data
df_weekly <- df %>%
group_by(sku, date = yearweek(transaction_date)) %>%
summarise(gross_units=sum(gross_units,na.rm=TRUE))
# Convert to tsibble (time series tibble) with SKU as key
df.ts <- df_weekly %>%
as_tsibble(index=date,key=sku)
source("C:/Users/disal/Desktop/GitHubRepos/ForecastingProject/WeeklyHighDemand/WeeklyHighDemandData.Rmd")
source("C:/Users/disal/Desktop/GitHubRepos/ForecastingProject/WeeklyHighDemand/WeeklyHighDemandData.Rmd")
source("C:/Users/disal/Desktop/GitHubRepos/ForecastingProject/WeeklyHighDemand/WeeklyHighDemandData.Rmd")
View(counts)
# Read in data
df <- fread(file="WeeklyHighDemand.csv") %>%
select(-7:-12)
# Create weekly dataframe from daily data
df_weekly <- df %>%
group_by(sku, date = yearweek(transaction_date)) %>%
summarise(gross_units=sum(gross_units,na.rm=TRUE))
# Convert to tsibble (time series tibble) with SKU as key
df.ts <- df_weekly %>%
as_tsibble(index=date,key=sku)
# There are lots of skus with only a few observations
counts <- df.ts %>%
as_tibble() %>%
count(sku) %>%
arrange(desc(n))
View(counts)
source("C:/Users/disal/Desktop/GitHubRepos/ForecastingProject/WeeklyHighDemand/WeeklyHighDemandData.Rmd")
# Hhat is the median number of rows of data for each sku?
median(counts$n)
source("C:/Users/disal/Desktop/GitHubRepos/ForecastingProject/WeeklyHighDemand/WeeklyHighDemandData.Rmd")
