"0","# Read in data"
"0","df <- data.table::fread(file=""WeeklyHighDemand.csv"") %>% "
"0","  select(-7:-12) %>% "
"0","  mutate(sku=as.factor(sku),"
"0","         transaction_date=as.Date(transaction_date)) %>% "
"0","  as_tibble()  "
"0",""
"0","# Create weekly dataframe from daily data"
"0","df_weekly <- df %>% "
"0","  group_by(sku,date=yearweek(transaction_date)) %>% "
"0","  summarise(gross_units=sum(gross_units,na.rm=TRUE))"
"0",""
"0","# Filter to only those combos with the maximum of 187 weeks"
"0","df_weekly %<>% "
"0","  group_by(sku) %>% "
"0","  filter(n()==187)"
"0",""
"0","# Perform Ljung-Box test"
"0","lb <- df_weekly %>% "
"0","  group_by(sku) %>%"
"0","  summarise(test=ljung_box(gross_units,lag=52)[2])"
"0",""
"0","# How many of the time-series are white noise?"
"0","lb %<>% "
"0","  filter(test < 0.05) # 446 SKU's are not white noise"
"0",""
"0","# Filter main dataset down to those that are not white noise"
"0","df_weekly %<>% "
"0","  group_by(sku) %>% "
"0","  filter(sku %in% lb$sku)"
"0",""
"0","# Convert date vector back to base R ""date"" type"
"0","df_weekly %<>% "
"0","  mutate(date=as.Date(date)) %>% "
"0","  ungroup()"
"0",""
"0","# Remove large data frames to free up memory"
"0","rm(df,df.ts)"
