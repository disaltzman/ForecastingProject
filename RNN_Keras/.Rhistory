#| warning: false
#| echo: true
# Import libraries
import pandas as pd
import tensorflow as tf
import numpy as np
# Plotting libraries
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(rc={"figure.dpi":400, 'savefig.dpi':400})
# Import functions that will be needed
from numpy import array
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import RNN, SimpleRNN
from keras.preprocessing.sequence import TimeseriesGenerator
from keras.layers import Dropout
from keras.optimizers import Adam
from keras.layers.core import Activation
from keras.callbacks import EarlyStopping
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
# Set random seed
np.random.seed(401)
import pyjanitor
import janitor
#| warning: false
#| echo: true
# Read in data
df = (
pd.read_csv("keras_rnn_data.csv")
.rename(columns={'PERIOD_DATE':'DATE',
'PRODUNIT_ID':'ID',
'QTY':'QUANTITY'})
.sort_values(by=['DATE','ID'])
.astype({'DATE': 'datetime64[ns]'})
)
# Remove whitespace, dashes, and commas from quantity
df['QUANTITY'] = (
df['QUANTITY']
.str.strip()
.replace({'-':'0',',':''},regex=True)
.astype(int)
)
# Count # of observations for each SKU
print(df['ID'].
value_counts().
sort_values(ascending=False))
# Fill in missing days
import janitor
df = df.complete(
{'DATE': lambda date: pd.date_range(date.min(), date.max())},
by = ['ID'],
fill_value=0,
sort = True)
# Count # of observations after
print(df['ID'].
value_counts().
sort_values(ascending=False))
# Set index
df = df.set_index(['DATE'])
# Subset for testing purposes
df = df[df['ID'] == 'PICK-BULK'].reindex()
# Drop ID column as it is no longer needed
df = df.drop('ID',axis=1)
#| warning: false
#| echo: true
# Create various temporal features
df_features = (df
.assign(day = df.index.isocalendar().day)
.assign(month = df.index.month)
.assign(day_of_week = df.index.weekday)
.assign(week_of_year = df.index.isocalendar().week)
)
#| warning: false
#| echo: true
# Define the sizes for training, testing, and holdout sets
train_size = 0.8  # 80% of data for training
test_size = 0.2  # 20% of data for testing (will be further split into holdout data )
# Split the data into a training and test set first
train_data, test_data = train_test_split(df_features, test_size=test_size, shuffle=False)
# Then split the remaining data 50/50 (i.e., the "rightmost" portion of the original data) into a test and holdout set
test_data, holdout_data = train_test_split(test_data, test_size=0.5, shuffle=False)
# The resulting data are now split into training, testing, and holdout sets
print("Training data size:", len(train_data))
print("Testing data size:", len(test_data))
print("Holdout data size:", len(holdout_data))
#| warning: false
#| echo: true
# Get number of features and
n_features = train_data.shape[1]
lookback_length = 5
# create training generator
train_generator = TimeseriesGenerator(
train_data.values,
train_data.values[:,0].reshape((len(train_data.values), 1)),
length=lookback_length,
batch_size=len(train_data)
)
# create test generator
test_generator = TimeseriesGenerator(
test_data.values,
test_data.values[:,0].reshape((len(test_data.values), 1)),
length=lookback_length,
batch_size=1
)
# create holdout generator
hold_generator = TimeseriesGenerator(
holdout_data.values,
holdout_data.values[:,0].reshape((len(holdout_data.values), 1)),
length=lookback_length,
batch_size=1
)
#| warning: false
#| echo: true
print("timesteps, features:", lookback_length, n_features)
# Initialize model
model = Sequential()
# Add recurrence to model
model.add(SimpleRNN(4, activation='relu', input_shape=(lookback_length, n_features), return_sequences = False))
# Add fully connected layer
model.add(Dense(1, activation='relu'))
# Define optimizer
adam = Adam(learning_rate=0.001)
# Register the custom metric function with the Keras model.
model.compile(loss='mse',optimizer='adam',metrics = ['mse', 'mae'])
# Summarize model we've created
model.summary()
#| warning: false
#| echo: true
# Define early stopping rule
early_stopping = EarlyStopping(monitor='val_loss',
patience=5,
mode='auto',
min_delta=0.1,
restore_best_weights=True,
verbose=1)
# Fit RNN
score = model.fit(train_generator,
epochs=1000,
validation_data=test_generator,
callbacks=[early_stopping],
verbose=1)
# Evaluate model
model.evaluate(test_generator)
train_generator.data
train_generator.targets
train_generator = TimeseriesGenerator(
train_data.values.astype('float32'),
train_data.values[:,0].reshape((len(train_data.values), 1)).astype('float32'),
length=lookback_length,
batch_size=len(train_data)
)
train_generator.targets
train_generator.data
#| warning: false
#| echo: true
# Get number of features and
n_features = train_data.shape[1]
lookback_length = 5
# create training generator
train_generator = TimeseriesGenerator(
train_data.values.astype('float32'),
train_data.values[:,0].reshape((len(train_data.values), 1)).astype('float32'),
length=lookback_length,
batch_size=len(train_data)
)
# create test generator
test_generator = TimeseriesGenerator(
test_data.values.astype('float32'),
test_data.values[:,0].reshape((len(test_data.values), 1)).astype('float32'),
length=lookback_length,
batch_size=1
)
# create holdout generator
hold_generator = TimeseriesGenerator(
holdout_data.values.astype('float32'),
holdout_data.values[:,0].reshape((len(holdout_data.values), 1)).astype('float32'),
length=lookback_length,
batch_size=1
)
#| warning: false
#| echo: true
# Define early stopping rule
early_stopping = EarlyStopping(monitor='val_loss',
patience=5,
mode='auto',
min_delta=0.1,
restore_best_weights=True,
verbose=1)
# Fit RNN
score = model.fit(train_generator,
epochs=1000,
validation_data=test_generator,
callbacks=[early_stopping],
verbose=1)
# Evaluate model
model.evaluate(test_generator)
#| label: val_loss_fig
#| fig-cap: "Plot showing training and validation loss during model fitment"
#| warning: false
# Get training + validation loss
losses = score.history['loss']
val_losses = score.history['val_loss']
# Create a figure and axes
fig, ax = plt.subplots()
sns.set_style("darkgrid")
# Plot training and validation losses
sns.lineplot(x=range(len(losses)), y=losses, ax=ax, label="Training Loss")
sns.lineplot(x=range(len(val_losses)), y=val_losses, ax=ax, label="Validation Loss",linestyle="--")
# Set the title and labels of plot
ax.set_title("Training and Validation Losses")
ax.set_xlabel("Epoch")
ax.set_ylabel("Loss")
# Show plot
plt.show()
#| warning: false
#| echo: true
df_result = pd.DataFrame({'Actual' : [], 'Prediction' : []})
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
df_result = df_result.append({'Actual': y[0][0], 'Prediction':yhat[0][0]}, ignore_index=True)
# Calculate MASE
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
mase = MeanAbsoluteScaledError()
y_true = pd.Series(data=df_result['Actual'])
y_pred = pd.Series(data=df_result['Prediction'])
y_train = pd.Series(data=train_data['QUANTITY'])
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
df_result = pd.DataFrame({'Actual' : [], 'Prediction' : []})
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = np.array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
df_result = df_result.loc[len(df_result)]
df_result['Actual'] = y[0][0]
df_result['Prediction'] = yhat[0][0]
df_result = pd.DataFrame({'Actual': [], 'Prediction': []})
df_result = pd.DataFrame({'Actual': [], 'Prediction': []})
for i, (x, y) in enumerate(hold_generator):
x_input = x.reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
df_result = df_result.assign(Actual=y[0][0], Prediction=yhat[0][0])
df_result
df_result = pd.DataFrame({'Actual': [], 'Prediction': []})
enumerate(hold_generator)
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
df_result = df_result.assign(Actual=y[0][0], Prediction=yhat[0][0])
df_result
df_result = pd.DataFrame({'Actual' : [], 'Prediction' : []})
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
df_result = df_result.append({'Actual': y[0][0], 'Prediction':yhat[0][0]}, ignore_index=True)
results_list = []
results_list = []
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
results_list.append({'Actual': y[0][0], 'Prediction':yhat[0][0]})
df_result = pd.DataFrame(results_list)
len(hold_generator)
results_list = []
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
results_list.append({'Actual': y[0][0], 'Prediction':yhat[0][0]})
df_result = pd.DataFrame(results_list)
df_result
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
mase = MeanAbsoluteScaledError()
y_true = pd.Series(data=df_result['Actual'])
y_pred = pd.Series(data=df_result['Prediction'])
y_train = pd.Series(data=train_data['QUANTITY'])
y_pred
y_true
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
#| label: "predictions_plot"
#| fig-cap: "Plot of the actuals vs predictions made by the RNN on held out data"
# Create a figure and axes
fig, ax = plt.subplots()
# Plot training and validation losses
sns.lineplot(x=range(len(df_result)), y=df_result['Actual'], ax=ax, label="Actuals")
sns.lineplot(x=range(len(df_result)), y=df_result['Prediction'], ax=ax, label="Predictions")
# Set the title and labels of plot
ax.set_title("Actuals vs Predictions for Heldout Data")
ax.set_xlabel("Time")
ax.set_ylabel("Quantity")
ax.set(xticklabels=[])
# Show plot
plt.show()
model.predict(hold_generator)
model.predict(hold_generator).shape
holdout_data
model.predict(hold_generator)
hold_generator.data
hold_generator.data.shape
hold_generator.targets
hold_generator.targets.shape
#| label: "predictions_plot"
#| fig-cap: "Plot of the actuals vs predictions made by the RNN on held out data"
# Create a figure and axes
fig, ax = plt.subplots()
# Plot training and validation losses
sns.lineplot(x=range(len(df_result)), y=df_result['Actual'], ax=ax, label="Actuals")
sns.lineplot(x=range(len(df_result)), y=df_result['Prediction'], ax=ax, label="Predictions")
# Set the title and labels of plot
ax.set_title("Actuals vs Predictions for held out data")
ax.set_xlabel("Time")
ax.set_ylabel("Quantity")
ax.set(xticklabels=[])
# Show plot
plt.show()
#| label: "predictions_plot"
#| fig-cap: "Plot of the actuals vs predictions made by the RNN on held out data"
# Create a figure and axes
fig, ax = plt.subplots()
# Plot training and validation losses
sns.lineplot(x=range(len(df_result)), y=df_result['Actual'], ax=ax, label="Actuals")
sns.lineplot(x=range(len(df_result)), y=df_result['Prediction'], ax=ax, label="Predictions")
# Set the title and labels of plot
ax.set_title("Actuals vs predictions for held out data")
ax.set_xlabel("Time")
ax.set_ylabel("Quantity")
ax.set(xticklabels=[])
# Show plot
plt.show()
#| label: "predictions_plot"
#| fig-cap: "Plot of the actuals vs predictions made by the RNN on held out data"
# Create a figure and axes
fig, ax = plt.subplots()
# Plot training and validation losses
sns.lineplot(x=range(len(df_result)), y=df_result['Actual'], ax=ax, label="Actuals")
sns.lineplot(x=range(len(df_result)), y=df_result['Prediction'], ax=ax, label="Predictions")
# Set the title and labels of plot
ax.set_title("Actuals vs Predictions for Held Out Data")
ax.set_xlabel("Time")
ax.set_ylabel("Quantity")
ax.set(xticklabels=[])
# Show plot
plt.show()
model2 = Sequential()
model2.add(LSTM(4, activation='relu', input_shape=(lookback_length, n_features), return_sequences = False))
model2.add(Dense(1, activation='relu'))
adam = Adam(learning_rate=0.001)
model2.compile(loss='mse',optimizer='adam',metrics = ['mse', 'mae'])
model2.summary()
score2 = model2.fit(train_generator,
score2 = model2.fit(train_generator,
epochs=1000,
validation_data=test_generator,
callbacks=[early_stopping],
verbose=1)
model2.evaluate(hold_generator)
model.evaluate(hold_generator)
results_list2 = []
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
results_list2.append({'Actual': y[0][0], 'Prediction':yhat[0][0]})
df_result2 = pd.DataFrame(results_list)
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
mase = MeanAbsoluteScaledError()
y_true = pd.Series(data=df_result2['Actual'])
y_pred = pd.Series(data=df_result2['Prediction'])
y_train = pd.Series(data=train_data['QUANTITY'])
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
df_result2 = pd.DataFrame(results_list2)
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
mase = MeanAbsoluteScaledError()
y_true = pd.Series(data=df_result2['Actual'])
y_pred = pd.Series(data=df_result2['Prediction'])
y_train = pd.Series(data=train_data['QUANTITY'])
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
results_list2
df_result
df_result2
results_list2 = []
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model.predict(x_input, verbose=0)
results_list2.append({'Actual': y[0][0], 'Prediction':yhat[0][0]})
# Convert to dataframe
df_result2 = pd.DataFrame(results_list2)
df_result2
results_list2 = []
# Loop through actuals and get predictions from model
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model2.predict(x_input, verbose=0)
results_list2.append({'Actual': y[0][0], 'Prediction':yhat[0][0]})
# Convert to dataframe
df_result2 = pd.DataFrame(results_list2)
df_result2
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
mase = MeanAbsoluteScaledError()
y_true = pd.Series(data=df_result2['Actual'])
y_pred = pd.Series(data=df_result2['Prediction'])
y_train = pd.Series(data=train_data['QUANTITY'])
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
model2 = Sequential()
# Add recurrence to model
model2.add(LSTM(4, activation='relu', input_shape=(lookback_length, n_features), return_sequences = False))
model2.add(LSTM(4, activation='relu')
# Add fully connected layer
model2.add(Dense(1, activation='relu'))
# Define optimizer
adam = Adam(learning_rate=0.001)
# Register the custom metric function with the Keras model.
model2.compile(loss='mse',optimizer='adam',metrics = ['mse', 'mae'])
# Summarize model we've created
model2.summary()
# Initialize model
model2 = Sequential()
# Add recurrence to model
model2.add(LSTM(4, activation='relu', input_shape=(lookback_length, n_features), return_sequences = False))
model2.add(LSTM(4, activation='relu')
# Add fully connected layer
model2.add(Dense(1, activation='relu'))
# Define optimizer
adam = Adam(learning_rate=0.001)
# Register the custom metric function with the Keras model.
model2.compile(loss='mse',optimizer='adam',metrics = ['mse', 'mae'])
# Summarize model we've created
model2.summary()
# Fit model
score2 = model2.fit(train_generator,
epochs=1000,
validation_data=test_generator,
callbacks=[early_stopping],
verbose=1)
model2.evaluate(hold_generator)
model.evaluate(hold_generator)
# Create list to put results in
results_list2 = []
# Loop through actuals and get predictions from model
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model2.predict(x_input, verbose=0)
results_list2.append({'Actual': y[0][0], 'Prediction':yhat[0][0]})
# Convert to dataframe
df_result2 = pd.DataFrame(results_list2)
# Calculate MASE
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
mase = MeanAbsoluteScaledError()
y_true = pd.Series(data=df_result2['Actual'])
y_pred = pd.Series(data=df_result2['Prediction'])
y_train = pd.Series(data=train_data['QUANTITY'])
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
model2.summary()
model2 = Sequential()
# Add recurrence to model
model2.add(LSTM(4, activation='relu', input_shape=(lookback_length, n_features), return_sequences = True))
model2.add(LSTM(4, activation='relu')
# Add fully connected layer
model2.add(Dense(1, activation='relu'))
# Define optimizer
adam = Adam(learning_rate=0.001)
# Register the custom metric function with the Keras model.
model2.compile(loss='mse',optimizer='adam',metrics = ['mse', 'mae'])
# Summarize model we've created
model2.summary()
# Fit model
score2 = model2.fit(train_generator,
epochs=1000,
validation_data=test_generator,
callbacks=[early_stopping],
verbose=1)
model2.evaluate(hold_generator)
model.evaluate(hold_generator)
# Create list to put results in
results_list2 = []
# Loop through actuals and get predictions from model
for i in range(len(hold_generator)):
x, y = hold_generator[i]
x_input = array(x).reshape((1, lookback_length, n_features))
yhat = model2.predict(x_input, verbose=0)
results_list2.append({'Actual': y[0][0], 'Prediction':yhat[0][0]})
# Convert to dataframe
df_result2 = pd.DataFrame(results_list2)
# Calculate MASE
from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError
mase = MeanAbsoluteScaledError()
y_true = pd.Series(data=df_result2['Actual'])
y_pred = pd.Series(data=df_result2['Prediction'])
y_train = pd.Series(data=train_data['QUANTITY'])
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
View(yhat)
y_pred
print("MASE score:", round(mase(y_true=y_true,y_pred=y_pred,y_train=y_train),2))
df_result2
y_pred
reticulate::repl_python()
